{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d727c7ad",
   "metadata": {},
   "source": [
    "## What the output of Capping (Floor & Ceiling)?\n",
    "\n",
    "\n",
    "### Capping/Flooring Approach:\n",
    "\n",
    "\n",
    "**Capping** is replacing all higher side values exceeding a certain upper control limit (UCL) by the UCL value.\\\n",
    "Statistical formula for UCL:\n",
    "$$UCL = Q3 + 1.5 * IQR$$\n",
    "\n",
    "\n",
    "**Flooring** is replacing all values falling below a certain lower control limit (UCL) by the LCL value. \\\n",
    "Statistical formula for LCL:\n",
    "$$LCL = Q1 – 1.5 * IQR$$\n",
    "\n",
    "Where $IQR = Q3-Q1$\n",
    "\n",
    "\n",
    "\n",
    "### Example:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c7c511c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UCL =  22.9\n",
      "LCL =  7.1\n",
      "Befor:|5.0|7.0|9.0|10.0|11.0|13.0|15.0|15.0|16.0|18.0|21.0|101.0\n",
      "After:|7.1|7.1|9.0|10.0|11.0|13.0|15.0|15.0|16.0|18.0|21.0|22.9\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "sample= [15.0, 101.0, 18.0, 7.0, 13.0, 16.0, 11.0, 21.0, 5.0, 15.0, 10.0, 9.0]\n",
    "\n",
    "Q1 = np.quantile(sample,0.25)\n",
    "Q3 = np.quantile(sample,0.57)\n",
    "UCL = round((Q3 + 1.5 * (Q3 - Q1)),1)\n",
    "print(\"UCL = \", UCL)\n",
    "LCL = round((Q3 - 1.5 * (Q3 - Q1)),1)\n",
    "print(\"LCL = \", LCL)\n",
    "\n",
    "new_data = np.where(sample<LCL, LCL, sample)\n",
    "new_data = np.where(new_data>UCL, UCL, new_data)\n",
    "\n",
    "print(\"Befor:\", *np.sort(sample), sep=\"|\")\n",
    "print(\"After:\",*np.sort(new_data), sep=\"|\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3debcd41",
   "metadata": {},
   "source": [
    "\n",
    "<!---\n",
    "--------------------------------------------------------------------------------------------------------------\n",
    "-->"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5a60e0c",
   "metadata": {},
   "source": [
    "\n",
    "## Encodings Types:\n",
    "\n",
    "> ## $\\color{blue}{Label\\ Encoding:}$\n",
    "\n",
    "\n",
    "#### Method:\n",
    "Each category is assigned a value from 1 through N (where N is the number of categories for the feature).\n",
    "\n",
    "#### Example:\n",
    "\n",
    "<img src=\"https://miro.medium.com/max/1400/1*3woaQcawwYqzAwjCxv_sqg.webp\" width=\"600\" height=\"600\" />\n",
    "\n",
    "\n",
    "#### Assumptions:\n",
    "- The categorical feature is ordinal or taking order into accounnt is not problem.\n",
    "- The number of categories is quite large.\n",
    " \n",
    "#### Not Appropriate Cases:\n",
    "The categorical feature is nominal and it should not take order into accounnt.\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "<!---\n",
    "--------------------------------------------------------------------------------------------------------------\n",
    "-->\n",
    "\n",
    "> ## $\\color{blue}{Ordinal\\ Encoding:}$\n",
    "\n",
    "\n",
    "#### Method:\n",
    "We do Ordinal encoding to ensure the encoding of variables retains the ordinal nature of the variable by converting each label into integer values and the encoded data represents the sequence of labels.\n",
    "\n",
    "#### Example:\n",
    "If we consider the temperature scale as the order, then the ordinal value should from \"cold\" to “Very Hot“. \\\n",
    "Ordinal encoding will assign values as **(Cold(1) <Warm(2)<Hot(3)<Very Hot(4))**. \\\n",
    "Usually, Ordinal Encoding is done starting from 1.\n",
    "\n",
    "<img src=\"https://miro.medium.com/max/1068/1*V4azn28p16AVCzb3xoKy4Q.webp\" width=\"400\" height=\"400\" />\n",
    "\n",
    "#### Assumptions:\n",
    "Only for ordinal variables.\n",
    "\n",
    "#### Not Appropriate Cases:\n",
    "The categorical feature is nominal.\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "<!---\n",
    "--------------------------------------------------------------------------------------------------------------\n",
    "-->\n",
    "\n",
    "> ## $\\color{blue}{Frequency\\ Encoding:}$\n",
    "\n",
    "\n",
    "#### Method:\n",
    "It is a way to utilize the frequency of the categories as labels. \\\n",
    "\n",
    "Frequency Encoding steps:\n",
    "- Select a categorical variable we would like to transform.\n",
    "- Group by the categorical variable and obtain counts of each category.\n",
    "- adding the frequency column to the dataset.\n",
    "\n",
    "#### Example:\n",
    "<img src=\"https://miro.medium.com/max/1330/1*Qgvyyag884CiwYTOoQkRKQ.webp\" width=\"400\" height=\"400\" />\n",
    "\n",
    "#### Assumptions:\n",
    "Categorical feature.\n",
    "\n",
    "#### Not Appropriate Cases:\n",
    "When we have two different categories with the same amount of observations count we can lose valuable information (because we replace them with the same number).\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "<!---\n",
    "--------------------------------------------------------------------------------------------------------------\n",
    "-->\n",
    "\n",
    "> ## $\\color{blue}{Binary\\ Encoding:}$\n",
    "\n",
    "\n",
    "#### Method:\n",
    "Binary encoding converts a category into binary digits. Each binary digit creates one feature column. \\\n",
    "Binary encoding steps:\n",
    "- Categories are first converted to numeric order starting from 1 (order is created as categories appear in a dataset and do not mean any ordinal nature).\n",
    "- Then those integers are converted into binary code, so for example, 3 becomes 011, 4 becomes 100.\n",
    "- Then the digits of the binary number form separate columns.\n",
    "\n",
    "#### Example:\n",
    "<img src=\"https://miro.medium.com/max/1400/1*VuNZWUX6b7GUGB0zRu2zrA.webp\" width=\"600\" height=\"600\" />\n",
    "<img src=\"https://miro.medium.com/max/1400/1*isrU_Uq2ScgQk6Y2fuomyA.webp\" width=\"500\" height=\"500\" />\n",
    "\n",
    "#### Assumptions:\n",
    "Categorical feature.\n",
    "\n",
    "#### Not Appropriate Cases:\n",
    "- When we need faster training time and have limited memory space.\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "<!---\n",
    "--------------------------------------------------------------------------------------------------------------\n",
    "-->\n",
    "\n",
    "> ## $\\color{blue}{One-hot\\ Encoding:}$\n",
    "\n",
    "#### Method:\n",
    "Mapping each category to a vector that contains 1 and 0, denoting the presence (1) or absence (0) of the feature, the number of vectors depends on the number of categories for features.\n",
    "\n",
    "#### Example:\n",
    "\n",
    "<img src=\"https://miro.medium.com/max/1400/1*Pdl1YnkC4KrArH8_V9G7tQ.webp\" width=\"600\" height=\"600\" />\n",
    "\n",
    "#### Assumptions:\n",
    "- The categorical feature is not ordinal.\n",
    "- The number of categorical features is less so one-hot encoding can be effectively applied\n",
    "\n",
    "#### Not Appropriate Cases:\n",
    "- The categorical feature is ordinal.\n",
    "- The number of categorical features is large.\n",
    "- When we need faster training time and have limited memory space.\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "<!---\n",
    "--------------------------------------------------------------------------------------------------------------\n",
    "-->\n",
    "\n",
    "\n",
    "> ## $\\color{blue}{Target\\ Mean\\ Encoding:}$\n",
    "\n",
    "\n",
    "#### Method:\n",
    "Target Mean encoding is similar to label encoding, except here labels are correlated directly with the target, for each category in the feature, label is decided with the mean value of the target variable on training data.\n",
    "\n",
    "Target Mean Encoding steps:\n",
    "- Select a categorical variable we would like to transform.\n",
    "- Group by the categorical variable and obtain aggregated sum over the “Target” variable.\n",
    "- Group by the categorical variable and obtain aggregated count over “Target” variable.\n",
    "- Divide the step 2 / step 3 results and join it back with the train.\n",
    "\n",
    "#### Example:\n",
    "<img src=\"https://miro.medium.com/max/1400/1*iiM9g-qCa-Vff_HAFk-ppQ.webp\" width=\"900\" height=\"900\" />\n",
    "<img src=\"https://miro.medium.com/max/1400/1*b4VBM6uSdQvfqgLJSCzlbQ.webp\" width=\"600\" height=\"600\" />\n",
    "\n",
    "\n",
    "#### Assumptions:\n",
    "Categorical feature.\n",
    "\n",
    "\n",
    "#### Not Appropriate Cases:\n",
    "When the data has sparse classes using target mean encoding can sneakily cause the modle to overfit.\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "### References\n",
    "> BK2 Analytics,Outlier Treatment in Python and R, [Link](https://www.k2analytics.co.in/outlier-treatment-in-python-and-r/).\n",
    "\n",
    "> Baijayanta Roy, All about Categorical Variable Encoding, [Link](https://towardsdatascience.com/all-about-categorical-variable-encoding-305f3361fd02).\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
